"""
í†µê³„ë¶„ì„ ìœ í‹¸ë¦¬í‹°
@Author: ì´ê´‘í˜¸(leekh4232@gmail.com)
"""
import sys
import numpy as np
import seaborn as sb
from pca import pca
from math import sqrt
from tabulate import tabulate
from matplotlib import pyplot as plt

from pandas import DataFrame, MultiIndex, Series

from scipy import stats
from scipy.stats import t, pearsonr, spearmanr

from statsmodels.formula.api import ols, logit
from statsmodels.stats.outliers_influence import variance_inflation_factor

from sklearn.preprocessing import StandardScaler



def prettyPrint(df, headers="keys", tablefmt="psql", numalign="right", title="value"):

    if isinstance(df, Series):
        df=DataFrame(df,columns=[title])
        
    print(tabulate(df, headers=headers, tablefmt=tablefmt, numalign=numalign))


def getConfidenceInterval(data, clevel=0.95, isPrint=True):
    """
    ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

    Parameters
    -------
    - data: ë°ì´í„°
    - clevel: ì‹ ë¢°ìˆ˜ì¤€. ê¸°ë³¸ê°’ì€ 0.95

    Returns
    -------
    - cmin: ì‹ ë¢°êµ¬ê°„ í•˜í•œ
    - cmax: ì‹ ë¢°êµ¬ê°„ ìƒí•œ
    """
    n = len(data)                           # ìƒ˜í”Œ ì‚¬ì´ì¦ˆ
    dof = n - 1                             # ììœ ë„
    sample_mean = data.mean()               # í‘œë³¸ í‰ê· 
    sample_std = data.std(ddof=1)           # í‘œë³¸ í‘œì¤€ í¸ì°¨
    sample_std_error = sample_std / sqrt(n)  # í‘œë³¸ í‘œì¤€ì˜¤ì°¨

    # ì‹ ë¢°êµ¬ê°„
    cmin, cmax = t.interval(
        clevel, dof, loc=sample_mean, scale=sample_std_error)

    if isPrint:
        df = DataFrame({
            "ì‹ ë¢°êµ¬ê°„": [cmin, cmax]
        }, index=['í•˜í•œ', 'ìƒí•œ'])

        prettyPrint(df)
    else:
        return (cmin, cmax)


def pearson_r(df, isPrint=True):
    """
    í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„

    Returns
    -------
    - rdf: ìƒê´€ë¶„ì„ ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = df.columns
    n = len(names)
    pv = 0.05

    data = []

    for i in range(0, n):
        # ê¸°ë³¸ì ìœ¼ë¡œ i ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ iê°€ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ì¼ ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
        j = i + 1 if i < n - 1 else 0

        fields = names[i] + ' vs ' + names[j]
        s, p = pearsonr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s,
                    'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)

    if isPrint:
        prettyPrint(rdf)
    else:
        return rdf


def spearman_r(df, isPrint=True):
    """
    ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê´€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„

    Returns
    -------
    - rdf: ìƒê´€ë¶„ì„ ê²°ê³¼ ë°ì´í„° í”„ë ˆì„
    """
    names = df.columns
    n = len(names)
    pv = 0.05

    data = []

    for i in range(0, n):
        # ê¸°ë³¸ì ìœ¼ë¡œ i ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ iê°€ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ì¼ ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
        j = i + 1 if i < n - 1 else 0

        fields = names[i] + ' vs ' + names[j]
        s, p = spearmanr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s,
                    'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)

    if isPrint:
        prettyPrint(rdf)
    else:
        return rdf


class OlsResult:
    def __init__(self):
        self._x_train = None
        self._y_train = None
        self._train_pred = None
        self._x_test = None
        self._y_test = None
        self._test_pred = None
        self._model = None
        self._fit = None
        self._summary = None
        self._table = None
        self._result = None
        self._goodness = None
        self._varstr = None
        self._coef = None
        self._intercept = None
        self._trainRegMetric = None
        self._testRegMetric = None
    
    @property
    def x_train(self):
        return self._x_train

    @x_train.setter
    def x_train(self, value):
        self._x_train = value

    @property
    def y_train(self):
        return self._y_train

    @y_train.setter
    def y_train(self, value):
        self._y_train = value

    @property
    def train_pred(self):
        return self._train_pred

    @train_pred.setter
    def train_pred(self, value):
        self._train_pred = value

    @property
    def x_test(self):
        return self._x_test

    @x_test.setter
    def x_test(self, value):
        self._x_test = value

    @property
    def y_test(self):
        return self._y_test

    @y_test.setter
    def y_test(self, value):
        self._y_test = value

    @property
    def test_pred(self):
        return self._test_pred

    @test_pred.setter
    def test_pred(self, value):
        self._test_pred = value

    @property
    def model(self):
        """
        ë¶„ì„ëª¨ë¸
        """
        return self._model

    @model.setter
    def model(self, value):
        self._model = value

    @property
    def fit(self):
        """
        ë¶„ì„ê²°ê³¼ ê°ì²´
        """
        return self._fit

    @fit.setter
    def fit(self, value):
        self._fit = value

    @property
    def summary(self):
        """
        ë¶„ì„ê²°ê³¼ ìš”ì•½ ë³´ê³ 
        """
        return self._summary

    @summary.setter
    def summary(self, value):
        self._summary = value

    @property
    def table(self):
        """
        ê²°ê³¼í‘œ
        """
        return self._table

    @table.setter
    def table(self, value):
        self._table = value

    @property
    def result(self):
        """
        ê²°ê³¼í‘œ ë¶€ê°€ ì„¤ëª…
        """
        return self._result

    @result.setter
    def result(self, value):
        self._result = value

    @property
    def goodness(self):
        """
        ëª¨í˜• ì í•©ë„ ë³´ê³ 
        """
        return self._goodness

    @goodness.setter
    def goodness(self, value):
        self._goodness = value

    @property
    def varstr(self):
        """
        ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
        """
        return self._varstr

    @varstr.setter
    def varstr(self, value):
        self._varstr = value
    
    @property
    def coef(self):
        return self._coef

    @coef.setter
    def coef(self, value):
        self._coef = value

    @property
    def intercept(self):
        return self._intercept

    @intercept.setter
    def intercept(self, value):
        self._intercept = value

    @property
    def trainRegMetric(self):
        return self._trainRegMetric

    @trainRegMetric.setter
    def trainRegMetric(self, value):
        self._trainRegMetric = value

    @property
    def testRegMetric(self):
        return self._testRegMetric

    @testRegMetric.setter
    def testRegMetric(self, value):
        self._testRegMetric = value

    def setRegMetric(self, y_train, y_train_pred, y_test=None, y_test_pred=None):
        self.trainRegMetric = RegMetric(y_train, y_train_pred)

        if y_test is not None and y_test_pred is not None:
            self.testRegMetric = RegMetric(y_test, y_test_pred)


def myOls(data, y=None, x=None, expr=None):
    """
    íšŒê·€ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """

    # ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    df=data.copy()

    # ì¢…ì†ë³€ìˆ˜~ë…ë¦½ë³€ìˆ˜1+ë…ë¦½ë³€ìˆ˜2+ë…ë¦½ë³€ìˆ˜3+... í˜•íƒœì˜ ì‹ì„ ìƒì„±
    if not expr:
        #ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if type(x) != list:
            x=[x]
        expr="%s~%s" % (y, "+".join(x))
    
    else:
        x = []
        p = expr.find('~')
        y = expr[:p].strip()
        x_tmp = expr[p+1:]
        x_list = x_tmp.split('+')

        for i in x_list:
            k=i.strip()

            if k:
                x.append(k)

    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = ols(expr, data=data)
    # ë¶„ì„ ìˆ˜í–‰
    fit = model.fit()

    # íŒŒì´ì¬ ë¶„ì„ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•œë‹¤.
    summary = fit.summary()

    # íšŒê·€ ê³„ìˆ˜ (beta) ì¶”ì¶œ
    beta_values = fit.params.drop("Intercept")  # Intercept ë³€ìˆ˜ ì œì™¸

    # ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´
    my = {}

    for k in range(0, 3, 2):
        items = summary.tables[k].data
        # print(items)

        for item in items:
            # print(item)
            n = len(item)

            for i in range(0, n, 2):
                key = item[i].strip()[:-1]
                value = item[i+1].strip()

                if key and value:
                    my[key] = value

    # ë‘ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´í•˜ì—¬ myì— ì¶”ê°€
    my['variables'] = []
    name_list = list(data.columns)
    #print(name_list)

    for i, v in enumerate(summary.tables[1].data):
        if i == 0:
            continue

        # ë³€ìˆ˜ì˜ ì´ë¦„
        name = v[0].strip()

        vif = 0

        # InterceptëŠ” ì œì™¸
        if name in name_list:
            # ë³€ìˆ˜ì˜ ì´ë¦„ ëª©ë¡ì—ì„œ í˜„ì¬ ë³€ìˆ˜ê°€ ëª‡ ë²ˆì§¸ í•­ëª©ì¸ì§€ ì°¾ê¸° 
            j = name_list.index(name)
            vif = variance_inflation_factor(data, j)

        my['variables'].append({
            "name": name,
            "coef": v[1].strip(),
            "std err": v[2].strip(),
            "t": v[3].strip(),
            "P-value": v[4].strip(),
            "Beta": beta_values.get(name, 0),
            "VIF": vif,
        })

    # ê²°ê³¼í‘œë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµ¬ì„±
    mylist = []
    yname_list = []
    xname_list = []

    for i in my['variables']:
        if i['name'] == 'Intercept':
            continue

        yname_list.append(y)
        xname_list.append(i['name'])

        item = {
            "B": i['coef'],
            "í‘œì¤€ì˜¤ì°¨": i['std err'],
            "Î²": i['Beta'],
            "t": "%s*" % i['t'],
            "ìœ ì˜í™•ë¥ ": i['P-value'],
            "VIF": i["VIF"]
        }

        mylist.append(item)

    table = DataFrame(mylist,
                   index=MultiIndex.from_arrays([yname_list, xname_list], names=['ì¢…ì†ë³€ìˆ˜', 'ë…ë¦½ë³€ìˆ˜']))
    
    # ë¶„ì„ê²°ê³¼
    result = "ğ‘…(%s), ğ‘…^2(%s), ğ¹(%s), ìœ ì˜í™•ë¥ (%s), Durbin-Watson(%s)" % (my['R-squared'], my['Adj. R-squared'], my['F-statistic'], my['Prob (F-statistic)'], my['Durbin-Watson'])

    # ëª¨í˜• ì í•©ë„ ë³´ê³ 
    goodness = "%sì— ëŒ€í•˜ì—¬ %së¡œ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ë¶„ì„ì„ ì‹¤ì‹œí•œ ê²°ê³¼, ì´ íšŒê·€ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ %s(F(%s,%s) = %s, p < 0.05)." % (y, ",".join(x), "ìœ ì˜í•˜ë‹¤" if float(my['Prob (F-statistic)']) < 0.05 else "ìœ ì˜í•˜ì§€ ì•Šë‹¤", my['Df Model'], my['Df Residuals'], my['F-statistic'])

    # ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
    varstr = []

    for i, v in enumerate(my['variables']):
        if i == 0:
            continue
        
        s = "%sì˜ íšŒê·€ê³„ìˆ˜ëŠ” %s(p%s0.05)ë¡œ, %sì— ëŒ€í•˜ì—¬ %s."
        k = s % (v['name'], v['coef'], "<" if float(v['P-value']) < 0.05 else '>', y, 'ìœ ì˜ë¯¸í•œ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤' if float(v['P-value']) < 0.05 else 'ìœ ì˜í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤')

        varstr.append(k)

    ols_result = OlsResult()
    ols_result.model = model
    ols_result.fit = fit
    ols_result.summary = summary
    ols_result.table = table
    ols_result.result = result
    ols_result.goodness = goodness
    ols_result.varstr = varstr

    return ols_result


def scalling(df, yname=None):
    """
    ë°ì´í„° í”„ë ˆì„ì„ í‘œì¤€í™” í•œë‹¤.

    Parameters
    -------
    - df: ë°ì´í„° í”„ë ˆì„
    - yname: ì¢…ì†ë³€ìˆ˜ ì´ë¦„

    Returns
    -------
    - x_train_std_df: í‘œì¤€í™”ëœ ë…ë¦½ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    - y_train_std_df: í‘œì¤€í™”ëœ ì¢…ì†ë³€ìˆ˜ ë°ì´í„° í”„ë ˆì„
    """
    # í‰ì†Œì—ëŠ” ynameì„ ì œê±°í•œ í•­ëª©ì„ ì‚¬ìš©
    # ynameì´ ìˆì§€ ì•Šë‹¤ë©´ dfë¥¼ ë³µì‚¬
    x_train = df.drop([yname], axis=1) if yname else df.copy()
    x_train_std = StandardScaler().fit_transform(x_train)
    x_train_std_df = DataFrame(x_train_std, columns=x_train.columns)
    
    if yname:
        y_train = df.filter([yname])
        y_train_std = StandardScaler().fit_transform(y_train)
        y_train_std_df = DataFrame(y_train_std, columns=y_train.columns)

    if yname:
        result = (x_train_std_df, y_train_std_df)
    else:
        result = x_train_std_df

    return result


class LogitResult:
    def __init__(self):
        self._model = None    
        self._fit = None
        self._summary = None
        self._prs = None
        self._cmdf = None
        self._result_df = None
        self._odds_rate_df = None

    @property
    def model(self):
        return self._model

    @model.setter
    def model(self, value):
        self._model = value

    @property
    def fit(self):
        return self._fit

    @fit.setter
    def fit(self, value):
        self._fit = value

    @property
    def summary(self):
        return self._summary

    @summary.setter
    def summary(self, value):
        self._summary = value

    @property
    def prs(self):
        return self._prs

    @prs.setter
    def prs(self, value):
        self._prs = value

    @property
    def cmdf(self):
        return self._cmdf

    @cmdf.setter
    def cmdf(self, value):
        self._cmdf = value

    @property
    def result_df(self):
        return self._result_df

    @result_df.setter
    def result_df(self, value):
        self._result_df = value

    @property
    def odds_rate_df(self):
        return self._odds_rate_df

    @odds_rate_df.setter
    def odds_rate_df(self, value):
        self._odds_rate_df = value

